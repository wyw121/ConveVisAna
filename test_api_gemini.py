"""
ä¸¥æ ¼æŒ‰ç…§å•†å®¶æ•™ç¨‹æµ‹è¯• Gemini æ¨¡å‹
ç”¨ä»£ç äº‹å®è¯æ˜è¯¥ API æ˜¯å¦æ”¯æŒ Gemini
"""
import requests
import json
from openai import OpenAI

# å•†å®¶æä¾›çš„ä¿¡æ¯
BASEURL = "https://www.chataiapi.com/v1"
API_KEY = "sk-imaEI6SqImBTTfAn8wvPiIN5oHelnY0iRbPe4CKLrDqe4pEV"

print("=" * 80)
print("æµ‹è¯•æŠ¥å‘Š: å•†å®¶ API å¯¹ Gemini æ¨¡å‹çš„æ”¯æŒæƒ…å†µ")
print("=" * 80)
print(f"API Base URL: {BASEURL}")
print(f"æµ‹è¯•æ—¶é—´: 2025-01-18")
print(f"æµ‹è¯•ä¾æ®: å•†å®¶æä¾›çš„å®˜æ–¹æ•™ç¨‹ä»£ç \n")

# ============================================================================
# æµ‹è¯• 1: ä½¿ç”¨å•†å®¶æ•™ç¨‹çš„ç¬¬ä¸€ç§æ–¹å¼ (requests åº“)
# ============================================================================
print("\n" + "=" * 80)
print("ã€æµ‹è¯• 1ã€‘ä½¿ç”¨å•†å®¶æ•™ç¨‹ç¤ºä¾‹ä»£ç  - requests æ–¹å¼è°ƒç”¨ Gemini")
print("=" * 80)

gemini_models = [
    "gemini-1.5-pro",
    "gemini-1.5-flash", 
    "gemini-pro",
    "gemini-2.0-flash-exp",
    "gemini-exp-1206"
]

for model_name in gemini_models:
    print(f"\næµ‹è¯•æ¨¡å‹: {model_name}")
    print("-" * 80)
    
    # å®Œå…¨æŒ‰ç…§å•†å®¶æ•™ç¨‹çš„æ ¼å¼
    payload = json.dumps({
        "model": model_name,
        "messages": [
            {
                "role": "system",
                "content": "You are a helpful assistant."
            },
            {
                "role": "user",
                "content": "hello"
            }
        ]
    })
    
    # å•†å®¶æ•™ç¨‹çš„ URL æ‹¼æ¥æœ‰è¯¯,è¿™é‡ŒæŒ‰æ•™ç¨‹åŸæ ·
    url = BASEURL + "/chat/completions"
    
    headers = {
        'Accept': 'application/json',
        'Authorization': f'Bearer {API_KEY}',
        'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',
        'Content-Type': 'application/json'
    }
    
    try:
        response = requests.request("POST", url, headers=headers, data=payload)
        print(f"âœ“ HTTP çŠ¶æ€ç : {response.status_code}")
        
        # è§£æå“åº”
        data = response.json()
        print(f"âœ“ å“åº”æ•°æ®: {json.dumps(data, ensure_ascii=False, indent=2)}")
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if response.status_code == 200 and 'choices' in data:
            content = data['choices'][0]['message']['content']
            print(f"âœ… æ¨¡å‹ {model_name} è°ƒç”¨æˆåŠŸ!")
            print(f"   å›å¤å†…å®¹: {content}")
        else:
            print(f"âŒ æ¨¡å‹ {model_name} è°ƒç”¨å¤±è´¥!")
            if 'error' in data:
                print(f"   é”™è¯¯ä¿¡æ¯: {data['error']}")
    
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")

# ============================================================================
# æµ‹è¯• 2: ä½¿ç”¨å•†å®¶æ•™ç¨‹çš„ç¬¬äºŒç§æ–¹å¼ (OpenAI å®¢æˆ·ç«¯)
# ============================================================================
print("\n\n" + "=" * 80)
print("ã€æµ‹è¯• 2ã€‘ä½¿ç”¨å•†å®¶æ•™ç¨‹ç¤ºä¾‹ä»£ç  - OpenAI å®¢æˆ·ç«¯æ–¹å¼è°ƒç”¨ Gemini")
print("=" * 80)

client = OpenAI(
    api_key=API_KEY,
    base_url=BASEURL
)

for model_name in gemini_models:
    print(f"\næµ‹è¯•æ¨¡å‹: {model_name}")
    print("-" * 80)
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "user",
                    "content": "hello"
                }
            ],
            max_tokens=100
        )
        
        print(f"âœ… æ¨¡å‹ {model_name} è°ƒç”¨æˆåŠŸ!")
        print(f"   å›å¤å†…å®¹: {response.choices[0].message.content}")
    
    except Exception as e:
        print(f"âŒ æ¨¡å‹ {model_name} è°ƒç”¨å¤±è´¥!")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")

# ============================================================================
# æµ‹è¯• 3: æµ‹è¯•å•†å®¶å£°ç§°æ”¯æŒçš„æ¨¡å‹
# ============================================================================
print("\n\n" + "=" * 80)
print("ã€æµ‹è¯• 3ã€‘æµ‹è¯•å•†å®¶å£°ç§°æ”¯æŒçš„å…¶ä»–æ¨¡å‹ (å¯¹æ¯”éªŒè¯)")
print("=" * 80)

control_models = [
    "claude-3-5-sonnet-20240620",  # å•†å®¶æ•™ç¨‹ä¸­çš„ç¤ºä¾‹æ¨¡å‹
    "deepseek-chat",               # å·²çŸ¥å¯ç”¨çš„æ¨¡å‹
    "gpt-3.5-turbo",              # å¸¸è§çš„ OpenAI æ¨¡å‹
]

for model_name in control_models:
    print(f"\næµ‹è¯•æ¨¡å‹: {model_name}")
    print("-" * 80)
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "user",
                    "content": "hello"
                }
            ],
            max_tokens=100
        )
        
        print(f"âœ… æ¨¡å‹ {model_name} è°ƒç”¨æˆåŠŸ!")
        print(f"   å›å¤å†…å®¹: {response.choices[0].message.content}")
    
    except Exception as e:
        print(f"âŒ æ¨¡å‹ {model_name} è°ƒç”¨å¤±è´¥!")
        print(f"   é”™è¯¯ä¿¡æ¯: {str(e)}")

# ============================================================================
# æµ‹è¯• 4: å°è¯•è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
# ============================================================================
print("\n\n" + "=" * 80)
print("ã€æµ‹è¯• 4ã€‘å°è¯•è·å– API æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨")
print("=" * 80)

try:
    models_response = client.models.list()
    print("âœ“ æˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨:")
    print("-" * 80)
    for model in models_response.data:
        print(f"  - {model.id}")
        if 'gemini' in model.id.lower():
            print(f"    âœ… å‘ç° Gemini æ¨¡å‹!")
except Exception as e:
    print(f"âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {str(e)}")

# ============================================================================
# æ€»ç»“æŠ¥å‘Š
# ============================================================================
print("\n\n" + "=" * 80)
print("ğŸ“Š æµ‹è¯•æ€»ç»“")
print("=" * 80)
print("""
æœ¬æ¬¡æµ‹è¯•ä¸¥æ ¼æŒ‰ç…§å•†å®¶æä¾›çš„æ•™ç¨‹ä»£ç è¿›è¡Œ:
1. âœ“ ä½¿ç”¨äº†å•†å®¶æä¾›çš„ Base URL
2. âœ“ ä½¿ç”¨äº†å•†å®¶æä¾›çš„ API Key  
3. âœ“ ä½¿ç”¨äº†å•†å®¶æ•™ç¨‹ä¸­çš„ä¸¤ç§è°ƒç”¨æ–¹å¼
4. âœ“ æµ‹è¯•äº†å¤šä¸ª Gemini æ¨¡å‹ç‰ˆæœ¬

æµ‹è¯•ç»“æœå°†æ¸…æ¥šæ˜¾ç¤º:
- å“ªäº›æ¨¡å‹å¯ä»¥æ­£å¸¸è°ƒç”¨
- å“ªäº›æ¨¡å‹è¿”å›é”™è¯¯
- é”™è¯¯çš„å…·ä½“åŸå› 

å¦‚æœ Gemini æ¨¡å‹å…¨éƒ¨å¤±è´¥,è€Œå…¶ä»–æ¨¡å‹(å¦‚ Claude/DeepSeek)æˆåŠŸ,
åˆ™å¯ä»¥è¯æ˜å•†å®¶çš„ API ä¸æ”¯æŒ Gemini,ä¸æ•™ç¨‹æ˜¯å¦æ­£ç¡®æ— å…³ã€‚
""")
